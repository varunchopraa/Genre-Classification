{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/varunchopra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/varunchopra/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/varunchopra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading the input from lyrics file.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blues': 56, 'disco': 85, 'hiphop': 93, 'pop': 58, 'reggae': 85}\n",
      "{'blues': 10001, 'disco': 23073, 'hiphop': 47914, 'pop': 18786, 'reggae': 22948}\n"
     ]
    }
   ],
   "source": [
    "stop_words = (stopwords.words('english'))\n",
    "newsw=['youve','youd','youll','shes','ive','hes','cant','never','dont','one','didnt']\n",
    "stop_words.extend(newsw)\n",
    "\n",
    "songCount = dict()\n",
    "wordCount = dict()\n",
    "\n",
    "header = ['word', 'frequency', 'genre']\n",
    "\n",
    "with open(f'Documents/genres2/freqDict.csv', 'w', newline = \"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# a list of all the present genres\n",
    "# genresList = ['blues_lyrics', 'country_lyrics', 'disco_lyrics', 'hiphop_lyrics', 'metal_lyrics', 'pop_lyrics', 'reggae_lyrics', 'rock_lyrics']\n",
    "genresList = ['blues_lyrics', 'disco_lyrics', 'hiphop_lyrics', 'pop_lyrics', 'reggae_lyrics']\n",
    "\n",
    "# iterating over the list of all the genres in the genreList\n",
    "for genreName in genresList:\n",
    "    \n",
    "    songCount[genreName.replace('_lyrics','')] = 0\n",
    "    \n",
    "    genreLyrics = ''\n",
    "    lyricStopped = list()\n",
    "    \n",
    "    # getting the path of the current genre\n",
    "    genre = os.listdir(f'Documents/genres2/{genreName}')\n",
    "    \n",
    "    # selecting each song from each genre\n",
    "    for song in genre:\n",
    "        path = f'Documents/genres2/{genreName}/{song}'\n",
    "        \n",
    "        if song == '.DS_Store':\n",
    "            continue\n",
    "            \n",
    "        # counting songs per genre    \n",
    "        songCount[genreName.replace('_lyrics','')] += 1\n",
    "        \n",
    "        # defining the path of a song lyrics file\n",
    "        songname = open(path, 'r')\n",
    "        \n",
    "        # read all the words in lower case\n",
    "        lyric = songname.read().lower()\n",
    "        \n",
    "        # removing punctuations\n",
    "        for punct in string.punctuation:\n",
    "            lyric = lyric.replace(punct, '')\n",
    "        \n",
    "        # adding lyrics to genreLyrics list\n",
    "        genreLyrics += lyric\n",
    "    \n",
    "    # extracting words from a particular genreLyrics\n",
    "    words = genreLyrics.split()\n",
    "    \n",
    "    # counting words per genre\n",
    "    wordCount[genreName.replace('_lyrics','')] = len(words)\n",
    "    \n",
    "    # removing numbers\n",
    "    words = [x for x in words if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "    \n",
    "    # lemmatized words\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    words = [lmtzr.lemmatize(x) for x in words]\n",
    "    \n",
    "    # removing the stopwords\n",
    "    for l in words:\n",
    "        if l not in stop_words:\n",
    "            lyricStopped.append(l)\n",
    "            \n",
    "    # stemming\n",
    "    porter = PorterStemmer()\n",
    "    lyricStopped = [porter.stem(word) for word in lyricStopped]\n",
    "    \n",
    "    # frequency dictionary\n",
    "    freqDict = {}\n",
    "    \n",
    "    # counting the occurence of all the words in the dictionary\n",
    "    # no need to make a set of UNIQUE WORDS as the \"keys\" of this dictionary will all be unique\n",
    "    for word in lyricStopped:\n",
    "        freqDict[word] = freqDict.get(word, 0) + 1\n",
    "    # print the dictionary\n",
    "    with open(f'Documents/genres2/freqDict.csv', 'a', newline = \"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for key, value in freqDict.items():\n",
    "            writer.writerow([key, value, genreName.replace('_lyrics','')])\n",
    "            \n",
    "    \n",
    "            \n",
    "print(songCount)\n",
    "print(wordCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['true' 8]\n",
      " ['love' 83]\n",
      " ['goneha' 2]\n",
      " ...\n",
      " ['seat' 2]\n",
      " ['commot' 4]\n",
      " ['wind' 2]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Documents/genres2/freqDict.csv')\n",
    "X = dataset.iloc[:, [0,1]].values\n",
    "y = dataset.iloc[:, 2].values\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "dataset.groupby('genre').frequency.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10353, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=X[:,0]\n",
    "frequency=X[:,1]\n",
    "frequency= np.reshape(frequency,(-1,1))\n",
    "frequency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10353, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "word_encoded=le.fit_transform(word.astype(str))\n",
    "word_encoded = np.reshape(word_encoded,(-1,1))\n",
    "word_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10353, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.column_stack((word_encoded,frequency))\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size = 0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 240   0   0]\n",
      " [  0  11 318   1   0]\n",
      " [  0   9 925   6   0]\n",
      " [  0   6 226   0   0]\n",
      " [  0   4 323   2   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4519555770159343\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 240   0   0]\n",
      " [  0   0 330   0   0]\n",
      " [  0   0 940   0   0]\n",
      " [  0   0 232   0   0]\n",
      " [  0   0 329   0   0]]\n",
      "Accuracy: 0.45388701110574603\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 42)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 29  31 142  14  24]\n",
      " [ 34  57 196  14  29]\n",
      " [ 93 124 584  50  89]\n",
      " [ 26  37 124  23  22]\n",
      " [ 36  48 199  23  23]]\n",
      "Accuracy: 0.34572670207629164\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27  41 106  26  40]\n",
      " [ 44  49 155  35  47]\n",
      " [103 136 423 112 166]\n",
      " [ 24  39  99  35  35]\n",
      " [ 42  48 145  40  54]]\n",
      "Accuracy: 0.2839208112023177\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 238   0   2]\n",
      " [  0   0 327   1   2]\n",
      " [  0   0 928   2  10]\n",
      " [  0   0 228   0   4]\n",
      " [  0   0 323   1   5]]\n",
      "Accuracy: 0.4505070014485756\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4519555770159343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8282/8282 [==============================] - 0s 30us/step - loss: -8804.1575 - accuracy: 0.1502\n",
      "Epoch 2/20\n",
      "8282/8282 [==============================] - 0s 13us/step - loss: -62592.8853 - accuracy: 0.1502\n",
      "Epoch 3/20\n",
      "8282/8282 [==============================] - 0s 13us/step - loss: -245020.6853 - accuracy: 0.1502\n",
      "Epoch 4/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -689337.1908 - accuracy: 0.1502\n",
      "Epoch 5/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -1571446.6360 - accuracy: 0.1502\n",
      "Epoch 6/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -3066220.3778 - accuracy: 0.1502\n",
      "Epoch 7/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -5412076.3200 - accuracy: 0.1502\n",
      "Epoch 8/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -8782652.3330 - accuracy: 0.1502\n",
      "Epoch 9/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -13393881.5112 - accuracy: 0.1502\n",
      "Epoch 10/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -19416149.2185 - accuracy: 0.1502\n",
      "Epoch 11/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -27087302.3178 - accuracy: 0.1502\n",
      "Epoch 12/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -36423985.9309 - accuracy: 0.1502\n",
      "Epoch 13/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -47725392.9186 - accuracy: 0.1502\n",
      "Epoch 14/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -61066239.3393 - accuracy: 0.1502\n",
      "Epoch 15/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -76614781.3011 - accuracy: 0.1502\n",
      "Epoch 16/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -94550070.7230 - accuracy: 0.1502\n",
      "Epoch 17/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -114937367.0823 - accuracy: 0.1502\n",
      "Epoch 18/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -137912642.3956 - accuracy: 0.1502\n",
      "Epoch 19/20\n",
      "8282/8282 [==============================] - 0s 11us/step - loss: -163762500.8143 - accuracy: 0.1502\n",
      "Epoch 20/20\n",
      "8282/8282 [==============================] - 0s 12us/step - loss: -192137682.3724 - accuracy: 0.1502\n",
      "2071/2071 [==============================] - 0s 28us/step\n",
      "test_acc:  0.15934331715106964\n"
     ]
    }
   ],
   "source": [
    "# # NN?\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras import layers\n",
    "\n",
    "# input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(layers.Dense(512, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# # y_train = encoder.fit_transform(y_train)\n",
    "# # y_test = encoder.fit_transform(y_test)\n",
    "# y_enc = encoder.fit_transform(y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, y_enc, test_size = 0.2, random_state = 15)\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=20, batch_size=256)\n",
    "\n",
    "# # loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "# # print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "# # loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "# # print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "# # calculate accuracy\n",
    "# test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "# print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8282/8282 [==============================] - 0s 36us/step - loss: 1.5763 - accuracy: 0.4131\n",
      "Epoch 2/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4469 - accuracy: 0.4466\n",
      "Epoch 3/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4423 - accuracy: 0.4474\n",
      "Epoch 4/20\n",
      "8282/8282 [==============================] - 0s 18us/step - loss: 1.4402 - accuracy: 0.4463\n",
      "Epoch 5/20\n",
      "8282/8282 [==============================] - 0s 18us/step - loss: 1.4392 - accuracy: 0.4472\n",
      "Epoch 6/20\n",
      "8282/8282 [==============================] - 0s 20us/step - loss: 1.4386 - accuracy: 0.4475\n",
      "Epoch 7/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4382 - accuracy: 0.4469\n",
      "Epoch 8/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4401 - accuracy: 0.4460\n",
      "Epoch 9/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4395 - accuracy: 0.4476\n",
      "Epoch 10/20\n",
      "8282/8282 [==============================] - 0s 20us/step - loss: 1.4362 - accuracy: 0.4472\n",
      "Epoch 11/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4360 - accuracy: 0.4472\n",
      "Epoch 12/20\n",
      "8282/8282 [==============================] - 0s 18us/step - loss: 1.4359 - accuracy: 0.4474\n",
      "Epoch 13/20\n",
      "8282/8282 [==============================] - 0s 18us/step - loss: 1.4357 - accuracy: 0.4474\n",
      "Epoch 14/20\n",
      "8282/8282 [==============================] - 0s 18us/step - loss: 1.4345 - accuracy: 0.4472\n",
      "Epoch 15/20\n",
      "8282/8282 [==============================] - 0s 20us/step - loss: 1.4352 - accuracy: 0.4472\n",
      "Epoch 16/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4354 - accuracy: 0.4471\n",
      "Epoch 17/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4353 - accuracy: 0.4477\n",
      "Epoch 18/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4361 - accuracy: 0.4471\n",
      "Epoch 19/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4347 - accuracy: 0.4471\n",
      "Epoch 20/20\n",
      "8282/8282 [==============================] - 0s 19us/step - loss: 1.4345 - accuracy: 0.4469\n",
      "2071/2071 [==============================] - 0s 25us/step\n",
      "test_acc:  0.453887015581131\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='sigmoid'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(X_train,y_train,epochs=20,batch_size=64)\n",
    "\n",
    "# calculate accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "print('test_acc: ',test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
